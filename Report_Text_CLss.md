### Групповое задание по теме «Классификация текста». Кейс "Анализ тональности: Классификация отзывов (фильмов, продуктов, твитов) как позитивных, негативных или нейтральных"
#### Команда
1. Кипина Анна Владимировна
2. Лобачев Василий Иванович
#### Google colab
Ссылка: https://colab.research.google.com/drive/134COkXOT674ANKki0pBrye0sneLeABXH?hl=ru#scrollTo=AM8YAgaKD274

### Описание датасета
1. Ссылка: https://www.kaggle.com/datasets/arhamrumi/amazon-product-reviews
   - Датасет содержит отзывы покупателей о различных продуктах Amazon
2. Исходный размер: 5684540
   - Размер, с которым работали: 50000
3. Колонки: 'Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'
4. Количество шумных данных: 0.08%
5. Превалируют положительные оценки (> 50%)

### Предобработка данных 
1. Обработка пропусков:
   - Допустимы пропуски в колонке Summary, т.к. заголовки отзывов могут быть идентичными
   - Недопустимы пропуски в самих отзывах (Text). Отзыв **не должен быть пустым**. Пропуски по колонке Text очищаем
2. Категоризируем оценки:
   - 1-2: negative
   - 3: neutral
   - 4-5: positive
3. Объединяем вместе значения колонок Summary (заголовок отзыва) и Text (отзыв)
4. Приводим к нижнему регистру
5. Убираем пунктуацию
6. Лемматизация
7. Очистка стоп-слов
8. Разделение на выборки: тестовая и обучающая

### Классификация текста
Были рассмотрены 3 модели: Logistic Regression, Multinomial Naive Bayes и SVM
Для векторизации были использованы: TF-IDF и bag-of-words
#### Результаты:
<img width="403" height="787" alt="Screenshot_1" src="https://github.com/user-attachments/assets/2b49626c-48f7-42f8-80cd-17a58a0183ee" />

**Краткие выводы:**
1. Самая лучшая связка: SVM + TF-IDF (1-3)
   - **Accuracy = 0.8685**
2. Хуже всех работает связка: MNB + TF-IDF
3. MNB показала себя самой слабой из 3 моделей

### Результаты и анализ ошибок SVM + TF-IDF (1-3)

<img width="447" height="187" alt="image" src="https://github.com/user-attachments/assets/36932d03-f76d-4d16-bb87-57113da18b82" />

**Результаты по классам**
- Negative:
  - Precision = 0.70: 70% объектов, классифицированных как «негативные», действительно относятся к этому классу
  - Recall = 0.67: модель нашла 67% всех реальных негативных отзывов
  - F1-score = 0.69: сбалансированная метрика между точностью и полнотой — результат умеренный
  - Support = 1250: в выборке 1250 реальных негативных отзывов
- Neutral:
  - Precision = 0.49: только около 50% объектов, отнесённых к нейтральным, действительно нейтральны — высокая доля ложных срабатываний
  - Recall = 0.22: модель обнаруживает лишь 22% реальных нейтральных отзывов
  - F1-score = 0.30: низкий результат подтверждает слабость модели в работе с нейтральными текстами
  - Support = 688: в выборке 688 нейтральных отзывов
- Positive:
  - Precision = 0.91: 91% объектов, классифицированных как «позитивные», действительно таковы — высокая точность
  - Recall = 0.96: модель находит 96% всех реальных позитивных отзывов — практически полное определение
  - F1-score = 0.94: очень высокий сбалансированный результат
  - Support = 7326: в выборке 7326 позитивных отзывов (доминирующий)

**Глобальные метрики**
- Accuracy = 0.8685 (~0.87): 87% всех отзывов классифицированы правильно. Высокий результат обусловлен большим весом позитивного класса
- Macro avg:
  - Precision = 0.70
  - Recall = 0.62
  - F1-score = 0.64
  - Подчёркивает слабость в работе с нейтральными отзывами
- Weighted avg:
  - Precision = 0.85
  - Recall = 0.87
  - F1-score = 0.85
  - Доминирование позитивного класса «тянет» метрики вверх

**Выводы**
- Сильная сторона модели: отличная работа с позитивными отзывами
- Слабая сторона: серьёзные проблемы с нейтральными отзывами:
  - низкая полнота (Recall = 0.22) — пропускает большинство нейтральных текстов
  - невысокая точность (Precision = 0.49) — много ложных срабатываний
- Дисбаланс классов: огромное количество позитивных отзывов (7326) по сравнению с нейтральными (688) и негативными (1250) искажает общую картину — метрики «вздуваются» за счёт лёгкости классификации доминирующего класса

